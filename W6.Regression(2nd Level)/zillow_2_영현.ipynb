{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "zillow_2_영현.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-06T14:41:53.095035Z",
          "start_time": "2021-02-06T14:41:52.876140Z"
        },
        "id": "wMTGiFnwzUg4"
      },
      "source": [
        "# parameters\n",
        "FUDGE_FACTOR = 1.1200  # 이것으로 예측 곱하기\n",
        "\n",
        "XGB_WEIGHT = 0.6200\n",
        "BASELINE_WEIGHT = 0.0100\n",
        "OLS_WEIGHT = 0.0620\n",
        "NN_WEIGHT = 0.0800\n",
        "\n",
        "XGB1_WEIGHT = 0.8000  # 두 개의 XGB 모델을 결합한 첫 번째 가중치\n",
        "\n",
        "BASELINE_PRED = 0.0115   # 훈련 데이터의 평균을 기반으로 한 기준, Oleg 당\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import gc\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import random\n",
        "import datetime as dt\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout, BatchNormalization\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.layers.noise import GaussianDropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mepDMqrF0qzn",
        "outputId": "9264b566-7eed-4fd6-a9ed-f9779a98ef2e"
      },
      "source": [
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jflpUnA1b4Q",
        "outputId": "dcb385c4-8c98-4054-ba61-0c8807ad5465"
      },
      "source": [
        "import os\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "# folder 변수에 구글드라이브에 프로젝트를 저장한 디렉토리를 입력하세요!\r\n",
        "folder = \"Colab Notebooks\"\r\n",
        "project_dir = \"zillow\"\r\n",
        "\r\n",
        "base_path = Path(\"/content/gdrive/My Drive/\")\r\n",
        "project_path = base_path / folder / project_dir\r\n",
        "os.chdir(project_path)\r\n",
        "for x in list(project_path.glob(\"*\")):\r\n",
        "    if x.is_dir():\r\n",
        "        dir_name = str(x.relative_to(project_path))\r\n",
        "        os.rename(dir_name, dir_name.split(\" \", 1)[0])\r\n",
        "print(f\"현재 디렉토리 위치: {os.getcwd()}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "현재 디렉토리 위치: /content/gdrive/My Drive/Colab Notebooks/zillow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-06T14:29:29.204663Z",
          "start_time": "2021-02-06T14:28:53.615071Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HQv-xzdzUhI",
        "outputId": "519b5573-d443-4506-e20c-7d990138a31f"
      },
      "source": [
        "##### READ IN RAW DATA\n",
        "\n",
        "print( \"\\nReading data from disk ...\")\n",
        "prop = pd.read_csv('properties_2016.csv')\n",
        "train = pd.read_csv(\"train_2016_v2.csv\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading data from disk ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-02-06T14:30:18.918661Z",
          "start_time": "2021-02-06T14:30:18.842663Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DDKIx0oGzUhK",
        "outputId": "cb827ab3-6e4b-43b4-90cc-a7d569ef5085"
      },
      "source": [
        "prop.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>parcelid</th>\n",
              "      <th>airconditioningtypeid</th>\n",
              "      <th>architecturalstyletypeid</th>\n",
              "      <th>basementsqft</th>\n",
              "      <th>bathroomcnt</th>\n",
              "      <th>bedroomcnt</th>\n",
              "      <th>buildingclasstypeid</th>\n",
              "      <th>buildingqualitytypeid</th>\n",
              "      <th>calculatedbathnbr</th>\n",
              "      <th>decktypeid</th>\n",
              "      <th>finishedfloor1squarefeet</th>\n",
              "      <th>calculatedfinishedsquarefeet</th>\n",
              "      <th>finishedsquarefeet12</th>\n",
              "      <th>finishedsquarefeet13</th>\n",
              "      <th>finishedsquarefeet15</th>\n",
              "      <th>finishedsquarefeet50</th>\n",
              "      <th>finishedsquarefeet6</th>\n",
              "      <th>fips</th>\n",
              "      <th>fireplacecnt</th>\n",
              "      <th>fullbathcnt</th>\n",
              "      <th>garagecarcnt</th>\n",
              "      <th>garagetotalsqft</th>\n",
              "      <th>hashottuborspa</th>\n",
              "      <th>heatingorsystemtypeid</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>lotsizesquarefeet</th>\n",
              "      <th>poolcnt</th>\n",
              "      <th>poolsizesum</th>\n",
              "      <th>pooltypeid10</th>\n",
              "      <th>pooltypeid2</th>\n",
              "      <th>pooltypeid7</th>\n",
              "      <th>propertycountylandusecode</th>\n",
              "      <th>propertylandusetypeid</th>\n",
              "      <th>propertyzoningdesc</th>\n",
              "      <th>rawcensustractandblock</th>\n",
              "      <th>regionidcity</th>\n",
              "      <th>regionidcounty</th>\n",
              "      <th>regionidneighborhood</th>\n",
              "      <th>regionidzip</th>\n",
              "      <th>roomcnt</th>\n",
              "      <th>storytypeid</th>\n",
              "      <th>threequarterbathnbr</th>\n",
              "      <th>typeconstructiontypeid</th>\n",
              "      <th>unitcnt</th>\n",
              "      <th>yardbuildingsqft17</th>\n",
              "      <th>yardbuildingsqft26</th>\n",
              "      <th>yearbuilt</th>\n",
              "      <th>numberofstories</th>\n",
              "      <th>fireplaceflag</th>\n",
              "      <th>structuretaxvaluedollarcnt</th>\n",
              "      <th>taxvaluedollarcnt</th>\n",
              "      <th>assessmentyear</th>\n",
              "      <th>landtaxvaluedollarcnt</th>\n",
              "      <th>taxamount</th>\n",
              "      <th>taxdelinquencyflag</th>\n",
              "      <th>taxdelinquencyyear</th>\n",
              "      <th>censustractandblock</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10754147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34144442.0</td>\n",
              "      <td>-118654084.0</td>\n",
              "      <td>85768.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>010D</td>\n",
              "      <td>269.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.037800e+07</td>\n",
              "      <td>37688.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96337.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10759547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34140430.0</td>\n",
              "      <td>-118625364.0</td>\n",
              "      <td>4083.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0109</td>\n",
              "      <td>261.0</td>\n",
              "      <td>LCA11*</td>\n",
              "      <td>6.037800e+07</td>\n",
              "      <td>37688.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96337.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27516.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>27516.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10843547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73026.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>73026.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33989359.0</td>\n",
              "      <td>-118394633.0</td>\n",
              "      <td>63085.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1200</td>\n",
              "      <td>47.0</td>\n",
              "      <td>LAC2</td>\n",
              "      <td>6.037703e+07</td>\n",
              "      <td>51617.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>96095.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>650756.0</td>\n",
              "      <td>1413387.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>762631.0</td>\n",
              "      <td>20800.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10859147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5068.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5068.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34148863.0</td>\n",
              "      <td>-118437206.0</td>\n",
              "      <td>7521.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1200</td>\n",
              "      <td>47.0</td>\n",
              "      <td>LAC2</td>\n",
              "      <td>6.037141e+07</td>\n",
              "      <td>12447.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>27080.0</td>\n",
              "      <td>96424.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1948.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>571346.0</td>\n",
              "      <td>1156834.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>585488.0</td>\n",
              "      <td>14557.57</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10879947</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1776.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6037.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34194168.0</td>\n",
              "      <td>-118385816.0</td>\n",
              "      <td>8512.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1210</td>\n",
              "      <td>31.0</td>\n",
              "      <td>LAM1</td>\n",
              "      <td>6.037123e+07</td>\n",
              "      <td>12447.0</td>\n",
              "      <td>3101.0</td>\n",
              "      <td>46795.0</td>\n",
              "      <td>96450.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1947.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>193796.0</td>\n",
              "      <td>433491.0</td>\n",
              "      <td>2015.0</td>\n",
              "      <td>239695.0</td>\n",
              "      <td>5725.17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   parcelid  airconditioningtypeid  ...  taxdelinquencyyear  censustractandblock\n",
              "0  10754147                    NaN  ...                 NaN                  NaN\n",
              "1  10759547                    NaN  ...                 NaN                  NaN\n",
              "2  10843547                    NaN  ...                 NaN                  NaN\n",
              "3  10859147                    NaN  ...                 NaN                  NaN\n",
              "4  10879947                    NaN  ...                 NaN                  NaN\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPLNKd_c2TiA"
      },
      "source": [
        "## LightGBM\r\n",
        "#### Process Data For LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nd3cRW8n2aFw",
        "outputId": "e4078f05-98a1-43be-d47a-4f3494d1f2d6"
      },
      "source": [
        "print( \"\\nProcessing data for LightGBM ...\" )\r\n",
        "for c, dtype in zip(prop.columns, prop.dtypes):\t\r\n",
        "    if dtype == np.float64:\t\t\r\n",
        "        prop[c] = prop[c].astype(np.float32)\r\n",
        "\r\n",
        "df_train = train.merge(prop, how='left', on='parcelid')\r\n",
        "df_train.fillna(df_train.median(),inplace = True)\r\n",
        "\r\n",
        "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', \r\n",
        "                         'propertycountylandusecode', 'fireplacecnt', 'fireplaceflag'], axis=1)\r\n",
        "#x_train['Ratio_1'] = x_train['taxvaluedollarcnt']/x_train['taxamount']\r\n",
        "y_train = df_train['logerror'].values\r\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing data for LightGBM ...\n",
            "(90275, 53) (90275,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlTAoLHx2feO"
      },
      "source": [
        "train_columns = x_train.columns\r\n",
        "\r\n",
        "for c in x_train.dtypes[x_train.dtypes == object].index.values:\r\n",
        "    x_train[c] = (x_train[c] == True)\r\n",
        "\r\n",
        "del df_train; gc.collect() # 메모리 정리\r\n",
        "\r\n",
        "x_train = x_train.values.astype(np.float32, copy=False)\r\n",
        "d_train = lgb.Dataset(x_train, label=y_train)\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FffPWDJv2lyP",
        "outputId": "5e93d1fc-24e0-4764-e64f-da5b4f849a85"
      },
      "source": [
        "##### RUN LIGHTGBM\r\n",
        "\r\n",
        "params = {}\r\n",
        "params['max_bin'] = 10\r\n",
        "params['learning_rate'] = 0.0021 # shrinkage_rate\r\n",
        "params['boosting_type'] = 'gbdt'\r\n",
        "params['objective'] = 'regression'\r\n",
        "params['metric'] = 'l1'          # or 'mae'\r\n",
        "params['sub_feature'] = 0.345    # feature_fraction (small values => use very different submodels)\r\n",
        "params['bagging_fraction'] = 0.85 # sub_row\r\n",
        "params['bagging_freq'] = 40\r\n",
        "params['num_leaves'] = 512        # num_leaf\r\n",
        "params['min_data'] = 500         # min_data_in_leaf\r\n",
        "params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\r\n",
        "params['verbose'] = 0\r\n",
        "params['feature_fraction_seed'] = 2\r\n",
        "params['bagging_seed'] = 3\r\n",
        "\r\n",
        "np.random.seed(0)\r\n",
        "random.seed(0)\r\n",
        "\r\n",
        "print(\"\\nFitting LightGBM model ...\")\r\n",
        "clf = lgb.train(params, d_train, 430)\r\n",
        "\r\n",
        "del d_train; gc.collect()\r\n",
        "del x_train; gc.collect()\r\n",
        "\r\n",
        "print(\"\\nPrepare for LightGBM prediction ...\")\r\n",
        "print(\"   Read sample file ...\")\r\n",
        "sample = pd.read_csv('sample_submission.csv')\r\n",
        "print(\"   ...\")\r\n",
        "sample['parcelid'] = sample['ParcelId']\r\n",
        "print(\"   Merge with property data ...\")\r\n",
        "df_test = sample.merge(prop, on='parcelid', how='left')\r\n",
        "print(\"   ...\")\r\n",
        "del sample, prop; gc.collect()\r\n",
        "print(\"   ...\")\r\n",
        "#df_test['Ratio_1'] = df_test['taxvaluedollarcnt']/df_test['taxamount']\r\n",
        "x_test = df_test[train_columns]\r\n",
        "print(\"   ...\")\r\n",
        "del df_test; gc.collect()\r\n",
        "print(\"   Preparing x_test...\")\r\n",
        "for c in x_test.dtypes[x_test.dtypes == object].index.values:\r\n",
        "    x_test[c] = (x_test[c] == True)\r\n",
        "print(\"   ...\")\r\n",
        "x_test = x_test.values.astype(np.float32, copy=False)\r\n",
        "\r\n",
        "print(\"\\nStart LightGBM prediction ...\")\r\n",
        "p_test = clf.predict(x_test)\r\n",
        "\r\n",
        "del x_test; gc.collect()\r\n",
        "\r\n",
        "print( \"\\nUnadjusted LightGBM predictions:\" )\r\n",
        "print( pd.DataFrame(p_test).head() )\r\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting LightGBM model ...\n",
            "\n",
            "Prepare for LightGBM prediction ...\n",
            "   Read sample file ...\n",
            "   ...\n",
            "   Merge with property data ...\n",
            "   ...\n",
            "   ...\n",
            "   ...\n",
            "   Preparing x_test...\n",
            "   ...\n",
            "\n",
            "Start LightGBM prediction ...\n",
            "\n",
            "Unadjusted LightGBM predictions:\n",
            "          0\n",
            "0  0.030523\n",
            "1  0.032881\n",
            "2  0.010690\n",
            "3  0.009568\n",
            "4  0.009334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqwPRgqt28_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPGrT6IO4KOA"
      },
      "source": [
        "## XGBoost\r\n",
        "#### Re-read properties file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpc4ynZz4TM9",
        "outputId": "c1f6aa6d-d4db-4f6b-84de-0af6f62f0d96"
      },
      "source": [
        "print( \"\\nRe-reading properties file ...\")\r\n",
        "properties = pd.read_csv('properties_2016.csv')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Re-reading properties file ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahs3v8v74XHK",
        "outputId": "2d36b52b-364f-432c-8d22-88fe1d55a25d"
      },
      "source": [
        "##### PROCESS DATA FOR XGBOOST\r\n",
        "\r\n",
        "print( \"\\nProcessing data for XGBoost ...\")\r\n",
        "for c in properties.columns:\r\n",
        "    properties[c]=properties[c].fillna(-1)\r\n",
        "    if properties[c].dtype == 'object':\r\n",
        "        lbl = LabelEncoder()\r\n",
        "        lbl.fit(list(properties[c].values))\r\n",
        "        properties[c] = lbl.transform(list(properties[c].values))\r\n",
        "\r\n",
        "train_df = train.merge(properties, how='left', on='parcelid')\r\n",
        "x_train = train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\r\n",
        "x_test = properties.drop(['parcelid'], axis=1)\r\n",
        "# shape        \r\n",
        "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))\r\n",
        "\r\n",
        "# drop out ouliers\r\n",
        "train_df=train_df[ train_df.logerror > -0.4 ]\r\n",
        "train_df=train_df[ train_df.logerror < 0.419 ]\r\n",
        "x_train=train_df.drop(['parcelid', 'logerror','transactiondate'], axis=1)\r\n",
        "y_train = train_df[\"logerror\"].values.astype(np.float32)\r\n",
        "y_mean = np.mean(y_train)\r\n",
        "\r\n",
        "print('After removing outliers:')     \r\n",
        "print('Shape train: {}\\nShape test: {}'.format(x_train.shape, x_test.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing data for XGBoost ...\n",
            "Shape train: (90275, 57)\n",
            "Shape test: (2985217, 57)\n",
            "After removing outliers:\n",
            "Shape train: (88528, 57)\n",
            "Shape test: (2985217, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bYE8Iq64muh",
        "outputId": "22380dc7-f14d-4496-db1a-cd2d7292282e"
      },
      "source": [
        "##### RUN XGBOOST\r\n",
        "\r\n",
        "print(\"\\nSetting up data for XGBoost ...\")\r\n",
        "# xgboost params\r\n",
        "xgb_params = {\r\n",
        "    'eta': 0.037,\r\n",
        "    'max_depth': 5,\r\n",
        "    'subsample': 0.80,\r\n",
        "    'objective': 'reg:linear',\r\n",
        "    'eval_metric': 'mae',\r\n",
        "    'lambda': 0.8,   \r\n",
        "    'alpha': 0.4, \r\n",
        "    'base_score': y_mean,\r\n",
        "    'silent': 1\r\n",
        "}\r\n",
        "\r\n",
        "dtrain = xgb.DMatrix(x_train, y_train)\r\n",
        "dtest = xgb.DMatrix(x_test)\r\n",
        "\r\n",
        "num_boost_rounds = 250\r\n",
        "print(\"num_boost_rounds=\"+str(num_boost_rounds))\r\n",
        "\r\n",
        "# train model\r\n",
        "print( \"\\nTraining XGBoost ...\")\r\n",
        "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\r\n",
        "\r\n",
        "print( \"\\nPredicting with XGBoost ...\")\r\n",
        "xgb_pred1 = model.predict(dtest)\r\n",
        "\r\n",
        "print( \"\\nFirst XGBoost predictions:\" )\r\n",
        "print( pd.DataFrame(xgb_pred1).head() )"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up data for XGBoost ...\n",
            "num_boost_rounds=250\n",
            "\n",
            "Training XGBoost ...\n",
            "\n",
            "Predicting with XGBoost ...\n",
            "\n",
            "First XGBoost predictions:\n",
            "          0\n",
            "0 -0.037808\n",
            "1 -0.030016\n",
            "2  0.015642\n",
            "3  0.038718\n",
            "4 -0.010554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEwqPLoN4vcR",
        "outputId": "d1bead81-40f1-4bb0-e8e8-54f5574e7fc0"
      },
      "source": [
        "##### RUN XGBOOST AGAIN\r\n",
        "\r\n",
        "print(\"\\nSetting up data for XGBoost ...\")\r\n",
        "# xgboost params\r\n",
        "xgb_params = {\r\n",
        "    'eta': 0.033,\r\n",
        "    'max_depth': 6,\r\n",
        "    'subsample': 0.80,\r\n",
        "    'objective': 'reg:linear',\r\n",
        "    'eval_metric': 'mae',\r\n",
        "    'base_score': y_mean,\r\n",
        "    'silent': 1\r\n",
        "}\r\n",
        "\r\n",
        "num_boost_rounds = 150\r\n",
        "print(\"num_boost_rounds=\"+str(num_boost_rounds))\r\n",
        "\r\n",
        "print( \"\\nTraining XGBoost again ...\")\r\n",
        "model = xgb.train(dict(xgb_params, silent=1), dtrain, num_boost_round=num_boost_rounds)\r\n",
        "\r\n",
        "print( \"\\nPredicting with XGBoost again ...\")\r\n",
        "xgb_pred2 = model.predict(dtest)\r\n",
        "\r\n",
        "print( \"\\nSecond XGBoost predictions:\" )\r\n",
        "print( pd.DataFrame(xgb_pred2).head() )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up data for XGBoost ...\n",
            "num_boost_rounds=150\n",
            "\n",
            "Training XGBoost again ...\n",
            "\n",
            "Predicting with XGBoost again ...\n",
            "\n",
            "Second XGBoost predictions:\n",
            "          0\n",
            "0 -0.075882\n",
            "1 -0.022025\n",
            "2  0.025625\n",
            "3  0.060287\n",
            "4  0.026121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a3nWs3V4znq",
        "outputId": "df5c7829-493f-42ab-96ee-de62ceb9fd55"
      },
      "source": [
        "##### COMBINE XGBOOST RESULTS\r\n",
        "xgb_pred = XGB1_WEIGHT*xgb_pred1 + (1-XGB1_WEIGHT)*xgb_pred2\r\n",
        "#xgb_pred = xgb_pred1\r\n",
        "\r\n",
        "print( \"\\nCombined XGBoost predictions:\" )\r\n",
        "print( pd.DataFrame(xgb_pred).head() )\r\n",
        "\r\n",
        "del train_df\r\n",
        "del x_train\r\n",
        "del x_test\r\n",
        "del properties\r\n",
        "del dtest\r\n",
        "del dtrain\r\n",
        "del xgb_pred1\r\n",
        "del xgb_pred2 \r\n",
        "gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Combined XGBoost predictions:\n",
            "          0\n",
            "0 -0.045423\n",
            "1 -0.028418\n",
            "2  0.017638\n",
            "3  0.043031\n",
            "4 -0.003219\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0FFp1D941au"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX2G4y3x42cQ"
      },
      "source": [
        "## Neural Network\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMlkIeq45b_",
        "outputId": "b555304c-55ea-48fb-d96e-6eb88b26d1f7"
      },
      "source": [
        "# Read in data for neural network\r\n",
        "print( \"\\n\\nProcessing data for Neural Network ...\")\r\n",
        "print('\\nLoading train, prop and sample data...')\r\n",
        "train = pd.read_csv(\"train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\r\n",
        "prop = pd.read_csv('properties_2016.csv')\r\n",
        "sample = pd.read_csv('sample_submission.csv')\r\n",
        " \r\n",
        "print('Fitting Label Encoder on properties...')\r\n",
        "for c in prop.columns:\r\n",
        "    prop[c]=prop[c].fillna(-1)\r\n",
        "    if prop[c].dtype == 'object':\r\n",
        "        lbl = LabelEncoder()\r\n",
        "        lbl.fit(list(prop[c].values))\r\n",
        "        prop[c] = lbl.transform(list(prop[c].values))\r\n",
        "        \r\n",
        "print('Creating training set...')\r\n",
        "df_train = train.merge(prop, how='left', on='parcelid')\r\n",
        "\r\n",
        "df_train[\"transactiondate\"] = pd.to_datetime(df_train[\"transactiondate\"])\r\n",
        "df_train[\"transactiondate_year\"] = df_train[\"transactiondate\"].dt.year\r\n",
        "df_train[\"transactiondate_month\"] = df_train[\"transactiondate\"].dt.month\r\n",
        "df_train['transactiondate_quarter'] = df_train['transactiondate'].dt.quarter\r\n",
        "df_train[\"transactiondate\"] = df_train[\"transactiondate\"].dt.day\r\n",
        "\r\n",
        "print('Filling NA/NaN values...' )\r\n",
        "df_train.fillna(-1.0)\r\n",
        "\r\n",
        "print('Creating x_train and y_train from df_train...' )\r\n",
        "x_train = df_train.drop(['parcelid', 'logerror', 'transactiondate', 'propertyzoningdesc', 'propertycountylandusecode','fireplacecnt', 'fireplaceflag'], axis=1)\r\n",
        "y_train = df_train[\"logerror\"]\r\n",
        "\r\n",
        "y_mean = np.mean(y_train)\r\n",
        "print(x_train.shape, y_train.shape)\r\n",
        "train_columns = x_train.columns\r\n",
        "\r\n",
        "for c in x_train.dtypes[x_train.dtypes == object].index.values:\r\n",
        "    x_train[c] = (x_train[c] == True)\r\n",
        "\r\n",
        "print('Creating df_test...')\r\n",
        "sample['parcelid'] = sample['ParcelId']\r\n",
        "\r\n",
        "print(\"Merging Sample with property data...\")\r\n",
        "df_test = sample.merge(prop, on='parcelid', how='left')\r\n",
        "\r\n",
        "df_test[\"transactiondate\"] = pd.to_datetime('2016-11-15')  # placeholder value for preliminary version\r\n",
        "df_test[\"transactiondate_year\"] = df_test[\"transactiondate\"].dt.year\r\n",
        "df_test[\"transactiondate_month\"] = df_test[\"transactiondate\"].dt.month\r\n",
        "df_test['transactiondate_quarter'] = df_test['transactiondate'].dt.quarter\r\n",
        "df_test[\"transactiondate\"] = df_test[\"transactiondate\"].dt.day     \r\n",
        "x_test = df_test[train_columns]\r\n",
        "\r\n",
        "print('Shape of x_test:', x_test.shape)\r\n",
        "print(\"Preparing x_test...\")\r\n",
        "for c in x_test.dtypes[x_test.dtypes == object].index.values:\r\n",
        "    x_test[c] = (x_test[c] == True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Processing data for Neural Network ...\n",
            "\n",
            "Loading train, prop and sample data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting Label Encoder on properties...\n",
            "Creating training set...\n",
            "Filling NA/NaN values...\n",
            "Creating x_train and y_train from df_train...\n",
            "(90275, 56) (90275,)\n",
            "Creating df_test...\n",
            "Merging Sample with property data...\n",
            "Shape of x_test: (2985217, 56)\n",
            "Preparing x_test...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkMiYXWA5Vry",
        "outputId": "409b80df-5cb6-4dd7-c276-307141e0140a"
      },
      "source": [
        "## Preprocessing\r\n",
        "print(\"\\nPreprocessing neural network data...\")\r\n",
        "imputer= SimpleImputer()\r\n",
        "imputer.fit(x_train.iloc[:, :])\r\n",
        "x_train = imputer.transform(x_train.iloc[:, :])\r\n",
        "imputer.fit(x_test.iloc[:, :])\r\n",
        "x_test = imputer.transform(x_test.iloc[:, :])\r\n",
        "\r\n",
        "sc = StandardScaler()\r\n",
        "x_train = sc.fit_transform(x_train)\r\n",
        "x_test = sc.transform(x_test)\r\n",
        "\r\n",
        "len_x=int(x_train.shape[1])\r\n",
        "print(\"len_x is:\",len_x)\r\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preprocessing neural network data...\n",
            "len_x is: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJmPULSd5pl0",
        "outputId": "fc7a9bd3-b937-4891-866c-b71c317eafe9"
      },
      "source": [
        "# Neural Network\r\n",
        "print(\"\\nSetting up neural network model...\")\r\n",
        "nn = Sequential()\r\n",
        "nn.add(Dense(units = 400 , kernel_initializer = 'normal', input_dim = len_x))\r\n",
        "nn.add(PReLU())\r\n",
        "nn.add(Dropout(.4))\r\n",
        "nn.add(Dense(units = 160 , kernel_initializer = 'normal'))\r\n",
        "nn.add(PReLU())\r\n",
        "nn.add(BatchNormalization())\r\n",
        "nn.add(Dropout(.6))\r\n",
        "nn.add(Dense(units = 64 , kernel_initializer = 'normal'))\r\n",
        "nn.add(PReLU())\r\n",
        "nn.add(BatchNormalization())\r\n",
        "nn.add(Dropout(.5))\r\n",
        "nn.add(Dense(units = 26, kernel_initializer = 'normal'))\r\n",
        "nn.add(PReLU())\r\n",
        "nn.add(BatchNormalization())\r\n",
        "nn.add(Dropout(.6))\r\n",
        "nn.add(Dense(1, kernel_initializer='normal'))\r\n",
        "nn.compile(loss='mae', optimizer=Adam(lr=4e-3, decay=1e-4))\r\n",
        "\r\n",
        "print(\"\\nFitting neural network model...\")\r\n",
        "nn.fit(np.array(x_train), np.array(y_train), batch_size = 32, epochs = 70, verbose=2)\r\n",
        "\r\n",
        "print(\"\\nPredicting with neural network model...\")\r\n",
        "#print(\"x_test.shape:\",x_test.shape)\r\n",
        "y_pred_ann = nn.predict(x_test)\r\n",
        "\r\n",
        "print( \"\\nPreparing results for write...\" )\r\n",
        "nn_pred = y_pred_ann.flatten()\r\n",
        "print( \"Type of nn_pred is \", type(nn_pred) )\r\n",
        "print( \"Shape of nn_pred is \", nn_pred.shape )\r\n",
        "\r\n",
        "print( \"\\nNeural Network predictions:\" )\r\n",
        "print( pd.DataFrame(nn_pred).head() )"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Setting up neural network model...\n",
            "\n",
            "Fitting neural network model...\n",
            "Epoch 1/70\n",
            "2822/2822 - 13s - loss: 0.0713\n",
            "Epoch 2/70\n",
            "2822/2822 - 10s - loss: 0.0682\n",
            "Epoch 3/70\n",
            "2822/2822 - 10s - loss: 0.0682\n",
            "Epoch 4/70\n",
            "2822/2822 - 10s - loss: 0.0681\n",
            "Epoch 5/70\n",
            "2822/2822 - 10s - loss: 0.0680\n",
            "Epoch 6/70\n",
            "2822/2822 - 10s - loss: 0.0680\n",
            "Epoch 7/70\n",
            "2822/2822 - 10s - loss: 0.0679\n",
            "Epoch 8/70\n",
            "2822/2822 - 10s - loss: 0.0679\n",
            "Epoch 9/70\n",
            "2822/2822 - 10s - loss: 0.0678\n",
            "Epoch 10/70\n",
            "2822/2822 - 11s - loss: 0.0678\n",
            "Epoch 11/70\n",
            "2822/2822 - 10s - loss: 0.0678\n",
            "Epoch 12/70\n",
            "2822/2822 - 11s - loss: 0.0677\n",
            "Epoch 13/70\n",
            "2822/2822 - 10s - loss: 0.0677\n",
            "Epoch 14/70\n",
            "2822/2822 - 11s - loss: 0.0677\n",
            "Epoch 15/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 16/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 17/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 18/70\n",
            "2822/2822 - 11s - loss: 0.0676\n",
            "Epoch 19/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 20/70\n",
            "2822/2822 - 11s - loss: 0.0675\n",
            "Epoch 21/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 22/70\n",
            "2822/2822 - 10s - loss: 0.0676\n",
            "Epoch 23/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 24/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 25/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 26/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 27/70\n",
            "2822/2822 - 11s - loss: 0.0675\n",
            "Epoch 28/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 29/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 30/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 31/70\n",
            "2822/2822 - 10s - loss: 0.0675\n",
            "Epoch 32/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 33/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 34/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 35/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 36/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 37/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 38/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 39/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 40/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 41/70\n",
            "2822/2822 - 10s - loss: 0.0674\n",
            "Epoch 42/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 43/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 44/70\n",
            "2822/2822 - 11s - loss: 0.0673\n",
            "Epoch 45/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 46/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 47/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 48/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 49/70\n",
            "2822/2822 - 11s - loss: 0.0673\n",
            "Epoch 50/70\n",
            "2822/2822 - 11s - loss: 0.0673\n",
            "Epoch 51/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 52/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 53/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 54/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 55/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 56/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 57/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 58/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 59/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 60/70\n",
            "2822/2822 - 11s - loss: 0.0673\n",
            "Epoch 61/70\n",
            "2822/2822 - 11s - loss: 0.0673\n",
            "Epoch 62/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 63/70\n",
            "2822/2822 - 10s - loss: 0.0672\n",
            "Epoch 64/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 65/70\n",
            "2822/2822 - 10s - loss: 0.0672\n",
            "Epoch 66/70\n",
            "2822/2822 - 10s - loss: 0.0672\n",
            "Epoch 67/70\n",
            "2822/2822 - 10s - loss: 0.0672\n",
            "Epoch 68/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 69/70\n",
            "2822/2822 - 10s - loss: 0.0673\n",
            "Epoch 70/70\n",
            "2822/2822 - 10s - loss: 0.0672\n",
            "\n",
            "Predicting with neural network model...\n",
            "\n",
            "Preparing results for write...\n",
            "Type of nn_pred is  <class 'numpy.ndarray'>\n",
            "Shape of nn_pred is  (2985217,)\n",
            "\n",
            "Neural Network predictions:\n",
            "          0\n",
            "0 -0.008154\n",
            "1 -0.011216\n",
            "2  0.664503\n",
            "3  0.117354\n",
            "4  0.125193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVRjBade5vxz",
        "outputId": "7da02815-ca82-41d8-9df6-cbc360b0cfc4"
      },
      "source": [
        "# Cleanup\r\n",
        "del train\r\n",
        "del prop\r\n",
        "del sample\r\n",
        "del x_train\r\n",
        "del x_test\r\n",
        "del df_train\r\n",
        "del df_test\r\n",
        "del y_pred_ann\r\n",
        "gc.collect()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne7lrdox5zMh"
      },
      "source": [
        "## OLS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RX-V4Th5x6J",
        "outputId": "249f1849-03b1-47d2-ff24-5de6ec8ec43d"
      },
      "source": [
        "np.random.seed(17)\r\n",
        "random.seed(17)\r\n",
        "\r\n",
        "print( \"\\n\\nProcessing data for OLS ...\")\r\n",
        "\r\n",
        "train = pd.read_csv(\"train_2016_v2.csv\", parse_dates=[\"transactiondate\"])\r\n",
        "properties = pd.read_csv(\"properties_2016.csv\")\r\n",
        "submission = pd.read_csv(\"sample_submission.csv\")\r\n",
        "print(len(train),len(properties),len(submission))\r\n",
        "\r\n",
        "def get_features(df):\r\n",
        "    df[\"transactiondate\"] = pd.to_datetime(df[\"transactiondate\"])\r\n",
        "    df[\"transactiondate_year\"] = df[\"transactiondate\"].dt.year\r\n",
        "    df[\"transactiondate_month\"] = df[\"transactiondate\"].dt.month\r\n",
        "    df['transactiondate'] = df['transactiondate'].dt.quarter\r\n",
        "    df = df.fillna(-1.0)\r\n",
        "    return df\r\n",
        "\r\n",
        "def MAE(y, ypred):\r\n",
        "    #logerror=log(Zestimate)−log(SalePrice)\r\n",
        "    return np.sum([abs(y[i]-ypred[i]) for i in range(len(y))]) / len(y)\r\n",
        "\r\n",
        "train = pd.merge(train, properties, how='left', on='parcelid')\r\n",
        "y = train['logerror'].values\r\n",
        "test = pd.merge(submission, properties, how='left', left_on='ParcelId', right_on='parcelid')\r\n",
        "properties = [] #memory\r\n",
        "\r\n",
        "exc = [train.columns[c] for c in range(len(train.columns)) if train.dtypes[c] == 'O'] + ['logerror','parcelid']\r\n",
        "col = [c for c in train.columns if c not in exc]\r\n",
        "\r\n",
        "train = get_features(train[col])\r\n",
        "test['transactiondate'] = '2016-01-01' #should use the most common training date\r\n",
        "test = get_features(test[col])\r\n",
        "\r\n",
        "\r\n",
        "print(\"\\nFitting OLS...\")\r\n",
        "reg = LinearRegression(n_jobs=-1)\r\n",
        "reg.fit(train, y); print('fit...')\r\n",
        "print(MAE(y, reg.predict(train)))\r\n",
        "train = [];  y = [] #memory\r\n",
        "\r\n",
        "test_dates = ['2016-10-01','2016-11-01','2016-12-01','2017-10-01','2017-11-01','2017-12-01']\r\n",
        "test_columns = ['201610','201611','201612','201710','201711','201712']\r\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Processing data for OLS ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (22,32,34,49,55) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "90275 2985217 2985217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting OLS...\n",
            "fit...\n",
            "0.06836903603863123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6mRUTLW6ENk"
      },
      "source": [
        "## Combine and save\r\n",
        "#### Combine predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylWE1Q9f6BlV",
        "outputId": "c4444c1a-e2c5-4d4d-a9cc-3f1b499cd396"
      },
      "source": [
        "print( \"\\nCombining XGBoost, LightGBM, NN, and baseline predicitons ...\" )\r\n",
        "lgb_weight = 1 - XGB_WEIGHT - BASELINE_WEIGHT - NN_WEIGHT - OLS_WEIGHT \r\n",
        "lgb_weight0 = lgb_weight / (1 - OLS_WEIGHT)\r\n",
        "xgb_weight0 = XGB_WEIGHT / (1 - OLS_WEIGHT)\r\n",
        "baseline_weight0 =  BASELINE_WEIGHT / (1 - OLS_WEIGHT)\r\n",
        "nn_weight0 = NN_WEIGHT / (1 - OLS_WEIGHT)\r\n",
        "pred0 = 0\r\n",
        "pred0 += xgb_weight0*xgb_pred\r\n",
        "pred0 += baseline_weight0*BASELINE_PRED\r\n",
        "pred0 += lgb_weight0*p_test\r\n",
        "pred0 += nn_weight0*nn_pred\r\n",
        "\r\n",
        "print( \"\\nCombined XGB/LGB/NN/baseline predictions:\" )\r\n",
        "print( pd.DataFrame(pred0).head() )\r\n",
        "\r\n",
        "print( \"\\nPredicting with OLS and combining with XGB/LGB/NN/baseline predicitons: ...\" )\r\n",
        "for i in range(len(test_dates)):\r\n",
        "    test['transactiondate'] = test_dates[i]\r\n",
        "    pred = FUDGE_FACTOR * ( OLS_WEIGHT*reg.predict(get_features(test)) + (1-OLS_WEIGHT)*pred0 )\r\n",
        "    submission[test_columns[i]] = [float(format(x, '.4f')) for x in pred]\r\n",
        "    print('predict...', i)\r\n",
        "\r\n",
        "print( \"\\nCombined XGB/LGB/NN/baseline/OLS predictions:\" )\r\n",
        "print( submission.head() )\r\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Combining XGBoost, LightGBM, NN, and baseline predicitons ...\n",
            "\n",
            "Combined XGB/LGB/NN/baseline predictions:\n",
            "          0\n",
            "0 -0.023177\n",
            "1 -0.011625\n",
            "2  0.071054\n",
            "3  0.040900\n",
            "4  0.010941\n",
            "\n",
            "Predicting with OLS and combining with XGB/LGB/NN/baseline predicitons: ...\n",
            "predict... 0\n",
            "predict... 1\n",
            "predict... 2\n",
            "predict... 3\n",
            "predict... 4\n",
            "predict... 5\n",
            "\n",
            "Combined XGB/LGB/NN/baseline/OLS predictions:\n",
            "   ParcelId  201610  201611  201612  201710  201711  201712\n",
            "0  10754147 -0.0266 -0.0266 -0.0266 -0.0266 -0.0266 -0.0266\n",
            "1  10759547 -0.0149 -0.0149 -0.0149 -0.0149 -0.0149 -0.0149\n",
            "2  10843547  0.1197  0.1197  0.1197  0.1197  0.1197  0.1197\n",
            "3  10859147  0.0457  0.0457  0.0457  0.0457  0.0457  0.0457\n",
            "4  10879947  0.0137  0.0136  0.0136  0.0137  0.0136  0.0136\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-RIn6vz6L1O",
        "outputId": "a91d454d-abb8-4d12-cc1d-9221f0b13cb4"
      },
      "source": [
        "##### WRITE THE RESULTS\r\n",
        "\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "print( \"\\nWriting results to disk ...\" )\r\n",
        "submission.to_csv('sub{}.csv'.format(datetime.now().strftime('%Y%m%d_%H%M%S')), index=False)\r\n",
        "\r\n",
        "print( \"\\nFinished ...\")\r\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Writing results to disk ...\n",
            "\n",
            "Finished ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9NfgfJc6ML4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}