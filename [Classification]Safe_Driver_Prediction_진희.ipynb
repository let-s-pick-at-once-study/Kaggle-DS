{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Classification]Safe Driver Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWN8EU9neMNu"
      },
      "source": [
        "# Binary Classification\r\n",
        "## Tabular data\r\n",
        "- competition: [Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)\r\n",
        "- Kernel\r\n",
        "  - Base: [Data Preparation & Exploration](https://www.kaggle.com/bertcarremans/data-preparation-exploration)\r\n",
        "  - Model: [XGBoost CV (LB .284)](https://www.kaggle.com/aharless/xgboost-cv-lb-284)\r\n",
        "\r\n",
        "- **colab ver.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkeT4k_Tj9PM"
      },
      "source": [
        "# Data Preparation & Exploration\r\n",
        "\r\n",
        "1. Visual Inspection\r\n",
        "2. Defining the metadata\r\n",
        "3. Descriptive statistics\r\n",
        "4. Imbalanced classes\r\n",
        "5. Data quality checks\r\n",
        "6. EDA\r\n",
        "7. Feature engineering\r\n",
        "8. Feature selection\r\n",
        "9. Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l74JU3nplmYx"
      },
      "source": [
        "## Loading Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWOzyQvJlsjC"
      },
      "source": [
        "# Data handling\r\n",
        "import pandas as pd #데이터프레임\r\n",
        "import numpy as np #선형대수\r\n",
        "import matplotlib.pyplot as plt #시각화\r\n",
        "import seaborn as sns #시각화\r\n",
        "import warnings #warnings 방지\r\n",
        "warnings.filterwarnings('ignore') #warnings 무시-출력X\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "pd.set_option('display.max_columns',100) #최대 100개 칼럼까지만 출력하기 - 런타임 오류 방지\r\n",
        "\r\n",
        "# Preprocessing\r\n",
        "from sklearn.impute import SimpleImputer #결측값 대치\r\n",
        "from sklearn.preprocessing import PolynomialFeatures #??\r\n",
        "from sklearn.preprocessing import StandardScaler #표준화 scaler\r\n",
        "\r\n",
        "# Feature Selection\r\n",
        "from sklearn.feature_selection import VarianceThreshold #??\r\n",
        "from sklearn.feature_selection import SelectFromModel #??\r\n",
        "\r\n",
        "#??\r\n",
        "from sklearn.utils import shuffle #인덱스 셔플\r\n",
        "\r\n",
        "# Modeling\r\n",
        "from sklearn.ensemble import RandomForestClassifier #랜덤포레스트"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT11ly_Dpjjl"
      },
      "source": [
        "> `%matplotlib inline`의 UsageError\r\n",
        "`%matplotlib inline` 옆에 주석을 달면 *UsageError: unrecognized arguments* 에러가 발생\r\n",
        "- 예) `%matplotlib inline #그래프 안에 그리기`\r\n",
        "  - UsageError: unrecognized arguments: #그래프 안에 그리기\r\n",
        "- **해결**) 주석을 제거한다\r\n",
        "- [참고](https://stackoverflow.com/questions/27761707/cannot-plot-inline-with-ipython-notebook/28686533#28686533)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDeBXWdoqpf2"
      },
      "source": [
        "> colab에서 `sklearn.preprocessing.Imputer` import 불가\r\n",
        "- 예) `cannot import name 'Imputer'`\r\n",
        "- 원인) sklearn 버전 문제 (0.22.3 -> 0.21.3)\r\n",
        "- [참고](https://github.com/mindsdb/lightwood/issues/75)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waRaZyQF4l72"
      },
      "source": [
        "> sklearn 버전 update에 따른 Imputer 모듈 변환\r\n",
        "- 0.21.3 ver. `sklearn.preprocessing.Imputer`\r\n",
        "- 0.22.2부터 0.24.0까지 ver. `sklearn.impute.SimpleImputer`\r\n",
        "  1. `SimpleImputer(missing_values,strategy=[mean,median])` 일변량 특정값 대치(i번째 특정값만)\r\n",
        "  2. `IterativeImputer` 다변량 대치(i열을 출력으로 지정, 모델 추정치로 대치)\r\n",
        "    - R의 `missForest`같은 방법(랜덤포레스트로 결측값 대치)\r\n",
        "  3. `MissingIndicator(missing_values)` 결측여부 이진분류(결측치가 있는 열인지/결측치인지 아닌지) \r\n",
        "  4. `KNNImputer`  KNN 응용 결측치 대치\r\n",
        "  - [Imputer 선택 참고](https://scikit-learn.org/0.22/modules/impute.html#impute)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HjC5CxslpsW"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gmbxbh6Gj63"
      },
      "source": [
        "dir = 'drive/MyDrive/colab/kaggle/study/data/porto/'"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wllkc955lwmL"
      },
      "source": [
        "train = pd.read_csv(dir+'train.csv')\r\n",
        "test = pd.read_csv(dir+'test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQX51qQ0lxI_"
      },
      "source": [
        "# Visual Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ZeJuTSHMTQ"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lweXsasnHOmm"
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GovdTMAWHVuK"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOffDLFXHcsM"
      },
      "source": [
        "# 중복 제거 후 shape\r\n",
        "train.drop_duplicates()\r\n",
        "train.shape # 중복 값 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rshinl_iHlOf"
      },
      "source": [
        "test.shape #test는 중복 값 제거하지 않음->제출 폼 문제"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4fQAtPGHnnn"
      },
      "source": [
        "train.info() #모든 변수가 numeric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjZ6UBfXmkfI"
      },
      "source": [
        "# Defining the metadata\r\n",
        ": 변수의 특징을 담은 데이터\r\n",
        "- meta information\r\n",
        "  - role: input, target, ID\r\n",
        "  - level: nominal, interval, ordinal, binary\r\n",
        "  - keep(drop여부): True, False\r\n",
        "  - dtype: int, float, str"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esB5Uc7nfR95"
      },
      "source": [
        "data = []\r\n",
        "\r\n",
        "for f in train.columns:\r\n",
        "  # role - 변수 이름 기준으로\r\n",
        "  if f == 'target':\r\n",
        "    role = 'target'\r\n",
        "  elif f == 'id':\r\n",
        "    role = 'id'\r\n",
        "  else:\r\n",
        "    role = 'input'\r\n",
        "\r\n",
        "  # level - 변수 이름/타입 기준으로\r\n",
        "  if 'bin' in f or f == 'target':\r\n",
        "    level = 'binary'\r\n",
        "  elif 'cat' in f or f == 'id':\r\n",
        "    level = 'nominal'\r\n",
        "  elif train[f].dtype == float:\r\n",
        "    level = 'interval'\r\n",
        "  elif train[f].dtype == int:\r\n",
        "    level = 'ordinal'\r\n",
        "\r\n",
        "  # keep - id/외\r\n",
        "  keep = True #기본값\r\n",
        "  if f == 'id':\r\n",
        "    keep = False\r\n",
        "\r\n",
        "  # data type\r\n",
        "  dtype = train[f].dtype\r\n",
        "\r\n",
        "  # data 행 만들기(dict)\r\n",
        "  f_dict = {\r\n",
        "      'varname':f,\r\n",
        "      'role':role,\r\n",
        "      'level':level,\r\n",
        "      'keep':keep,\r\n",
        "      'dtype':dtype\r\n",
        "  }\r\n",
        "  data.append(f_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYtt6KbIQcxp"
      },
      "source": [
        "meta = pd.DataFrame(data, columns=['varname','role','level','keep','dtype'])\r\n",
        "meta.set_index('varname', inplace=True) #원래 True(index를 varname으로)->조건에 추가하려고 False로 변환\r\n",
        "\r\n",
        "meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ9oveDNvTMT"
      },
      "source": [
        "# ex. nominal 변수 출력\r\n",
        "meta[(meta.level == 'nominal') & (meta.keep)].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmgdXZT_v3KL"
      },
      "source": [
        "# 변수 정보 요약\r\n",
        "pd.DataFrame({\r\n",
        "    'count':meta.groupby(['role','level'])['role'].size()\r\n",
        "}).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D47-LLwmo4m"
      },
      "source": [
        "# Descriptive statistics\r\n",
        ": nominal제외 var. 요약 통계\r\n",
        "\r\n",
        "1. interval\r\n",
        "2. ordinal\r\n",
        "3. binary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTLrYjJrwvtk"
      },
      "source": [
        "## Interval var."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlJrpecQwOOx"
      },
      "source": [
        "v = meta[(meta.level=='interval') & (meta.keep)].index #조건에 맞는 변수명\r\n",
        "train[v].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNYFjas8xeH0"
      },
      "source": [
        "- **reg var.**\r\n",
        "  - *ps_reg_03*에 missing value 존재(-1은 missing value)\r\n",
        "  - min~max 범위가 제각각 -> scaling 필요\r\n",
        "\r\n",
        "- **car var.**\r\n",
        "  - *ps_car_12*, *ps_car_14*에 missing value 존재\r\n",
        "  - min~max 범위가 제각각 -> scaling 필요\r\n",
        "\r\n",
        "- **calc var.**\r\n",
        "  - missing value 없음\r\n",
        "  - min~max 범위 일치"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmVFOHzQwy83"
      },
      "source": [
        "## Ordinal var."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2KxmFRvw0tZ"
      },
      "source": [
        "v = meta[(meta.level=='ordinal') & (meta.keep)].index\r\n",
        "train[v].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SxGaFt3ysI0"
      },
      "source": [
        "- 유일하게 *ps_car_11*에 missing value 존재\r\n",
        "- min~max 범위 제각각 -> Scaler 사용 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkGJWIx-w0_j"
      },
      "source": [
        "## Binary var."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkFhmGC-w3JB"
      },
      "source": [
        "v = meta[(meta.level=='binary') & (meta.keep)].index\r\n",
        "train[v].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhjlDJESy02r"
      },
      "source": [
        "- binary 변수의 대부분이 `0`의 분포가 압도적으로 많은 편\r\n",
        "- 결측값은 없다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "namFlvs9mrgx"
      },
      "source": [
        "# Imbalanced classes\r\n",
        "- 문제) `target`변수의 0,1 비율이 불균형: 0이 압도적으로 많다\r\n",
        "  - 해결)\r\n",
        "    1. oversampling `target=1`\r\n",
        "    2. undersampling `target=0`\r\n",
        "  - training set 크기가 충분히 크기 때문에 **undersampling `target=0`**으로 처리한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZktsyjFqNbhT"
      },
      "source": [
        "desired_apriori = 0.10\r\n",
        "\r\n",
        "# target=0과 target=1 케이스\r\n",
        "idx_0 = train[train.target==0].index\r\n",
        "idx_1 = train[train.target==1].index\r\n",
        "\r\n",
        "# target value 개수\r\n",
        "nb_0 = len(train.loc[idx_0])\r\n",
        "nb_1 = len(train.loc[idx_1])\r\n",
        "print(f'target 0:{nb_0}({round(nb_0/train.shape[0]*100,2)}%)  1:{nb_1}({round(nb_1/train.shape[0]*100,2)}%)')\r\n",
        "\r\n",
        "# undersampling\r\n",
        "undersampling_rate = ((1-desired_apriori)*nb_1) / (desired_apriori*nb_0)\r\n",
        "undersampled_nb_0 = int(undersampling_rate*nb_0)\r\n",
        "print(f'Rate to undersample records with target=0:{round(undersampling_rate*100,2)}%')\r\n",
        "print(f'Number of records with target=0 after undersampling:{undersampled_nb_0}')\r\n",
        "\r\n",
        "# undersampled index (target=0)\r\n",
        "undersampled_idx = shuffle(idx_0, random_state=37, n_samples=undersampled_nb_0) #idx_0 중에서 undersampled_nb_0만큼\r\n",
        "\r\n",
        "# index list 합치기\r\n",
        "idx_list = list(undersampled_idx) + list(idx_1)\r\n",
        "\r\n",
        "# undersampled train set\r\n",
        "train = train.loc[idx_list].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "espzU7bBmxAW"
      },
      "source": [
        "# Data quality checks\r\n",
        "1. missing values\r\n",
        "2. cardinality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbOJNgLtz8DT"
      },
      "source": [
        "## Check missing values\r\n",
        "- 결측값은 -1로 표기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiDIX-Bh0O21"
      },
      "source": [
        "vars_with_missing = [] #missing value 존재하는 변수명\r\n",
        "\r\n",
        "for f in train.columns:\r\n",
        "  level = meta.loc[f,'level']\r\n",
        "  missings = train[train[f]==-1][f].count() #결측치(-1) 개수\r\n",
        "  if missings>0: #결측값 존재 시\r\n",
        "    vars_with_missing.append(f)\r\n",
        "    missings_perc = missings/train.shape[0]\r\n",
        "\r\n",
        "    print(f'{f}({level}) has {missings} records({round(missings_perc*100,2)}%)')\r\n",
        "\r\n",
        "print(f'\\n{len(vars_with_missing)} variables with missing values')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F7Fe3QU1mcc"
      },
      "source": [
        "- *ps_car_03_cat*(68.39%)와 *ps_car_05_cat*(44.26%)은 결측치 비율이 높아 **제거**한다\r\n",
        "- *ps_car_11*(ordinal)은 결측값이 1개 뿐이므로 **mode**값으로 채운다\r\n",
        "- 이하 변수들은 결측비율이 낮고 연속형 변수이므로 **mean**값으로 대체한다(categorical 변수 제외)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_uL_TeUhH7C"
      },
      "source": [
        "### drop columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1bexgDjXeZa"
      },
      "source": [
        "# drop columns\r\n",
        "vars_to_drop = ['ps_car_03_cat','ps_car_05_cat']\r\n",
        "train.drop(vars_to_drop, inplace=True, axis=1)\r\n",
        "meta.loc[(vars_to_drop),'keep'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDt3MBigaGzf"
      },
      "source": [
        "test.drop(vars_to_drop, inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9zLXNdmhMlx"
      },
      "source": [
        "### Imputing the mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Dc5167yZpu6"
      },
      "source": [
        "# Imputing the mode\r\n",
        "mode_imp = SimpleImputer(missing_values=-1, strategy='most_frequent')\r\n",
        "train['ps_car_11'] = mode_imp.fit_transform(train[['ps_car_11']]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7WQC80TaL6x"
      },
      "source": [
        "# test dset\r\n",
        "mode_imp = SimpleImputer(missing_values=-1, strategy='most_frequent')\r\n",
        "test['ps_car_11'] = mode_imp.fit_transform(test[['ps_car_11']]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4pHBlDuhOxT"
      },
      "source": [
        "### Imputing the mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMuMT5mFdIQE"
      },
      "source": [
        "# Imputing the mean\r\n",
        "mean_imp = SimpleImputer(missing_values=-1, strategy='mean')\r\n",
        "train['ps_reg_03'] = mean_imp.fit_transform(train[['ps_reg_03']]).ravel()\r\n",
        "train['ps_car_12'] = mean_imp.fit_transform(train[['ps_car_12']]).ravel()\r\n",
        "train['ps_car_14'] = mean_imp.fit_transform(train[['ps_car_14']]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN4sLa4_au2X"
      },
      "source": [
        "# test dset\r\n",
        "mean_imp = SimpleImputer(missing_values=-1, strategy='mean')\r\n",
        "test['ps_reg_03'] = mean_imp.fit_transform(test[['ps_reg_03']]).ravel()\r\n",
        "test['ps_car_12'] = mean_imp.fit_transform(test[['ps_car_12']]).ravel()\r\n",
        "test['ps_car_14'] = mean_imp.fit_transform(test[['ps_car_14']]).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgHx8sY70CJP"
      },
      "source": [
        "## Check the cardinality\r\n",
        "- **cardinality**: 집합원의 개수 [참고](http://www.dbguide.net/knowledge.db?cmd=view&boardConfigUid=30&boardUid=142699&boardStep=1)\r\n",
        "  - 예) 성별은 집단이 2개->cardinality가 낮은 속성\r\n",
        "  - 예) 주민번호는 집단이 무수히 많아 cardinality가 높은 속성\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTDol1u7fEzG"
      },
      "source": [
        "v = meta[(meta.level=='nominal') & (meta.keep)].index\r\n",
        "\r\n",
        "for f in v:\r\n",
        "  dist_values = train[f].value_counts().shape[0] #고유값 개수\r\n",
        "  print(f'Variable {f} has {dist_values} distinct values')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQcx-faLf-9u"
      },
      "source": [
        "- *ps_car_11_cat*이 많은 고유값을 가지고 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peW6S4aBQw0A"
      },
      "source": [
        "**이 파트 왜 하는지 솔직히 잘 모르겠음**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEPqWIK2hFH-"
      },
      "source": [
        "# Script by https://www.kaggle.com/ogrellier\r\n",
        "# Code: https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features\r\n",
        "\r\n",
        "def add_noise(series, noise_level):\r\n",
        "  return series * (1 + noise_level*np.random.randn(len(series)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2RhbEpFiEH7"
      },
      "source": [
        "# Smoothing is computed like in the following paper by Daniele Micci-Barreca\r\n",
        "# https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\r\n",
        "\r\n",
        "def target_encode(trn_series=None,# training categorical feature\r\n",
        "                  tst_series=None,# test categorical feature\r\n",
        "                  target=None,# target data\r\n",
        "                  min_samples_leaf=1,# minimum samples to take category average into account\r\n",
        "                  smoothing=1,# smoothing effect to balance categorical average vs prior\r\n",
        "                  noise_level=0):\r\n",
        "  assert len(trn_series)==len(target)\r\n",
        "  assert trn_series.name==tst_series.name\r\n",
        "  temp = pd.concat([trn_series, target],axis=1)\r\n",
        "\r\n",
        "  # target mean\r\n",
        "  averages = temp.groupby(by=trn_series.name)[target.name].agg(['mean','count'])\r\n",
        "\r\n",
        "  # smoothing\r\n",
        "  smoothing = 1 / (1+np.exp(-(averages['count']-min_samples_leaf)/smoothing))\r\n",
        "\r\n",
        "  # average to all target data\r\n",
        "  prior = target.mean()\r\n",
        "\r\n",
        "  # the bigger the count the less full_avg is taken into account\r\n",
        "  averages[target.name] = prior*(1-smoothing) + averages['mean']*smoothing\r\n",
        "  averages.drop(['mean','count'], axis=1, inplace=True)\r\n",
        "\r\n",
        "  # averages to trn and tst series\r\n",
        "  ft_trn_series = pd.merge(trn_series.to_frame(trn_series.name),\r\n",
        "                           averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\r\n",
        "                           on=trn_series.name,\r\n",
        "                           how='left')['average'].rename(trn_series.name+'_mean').fillna(prior)\r\n",
        "  \r\n",
        "  # drop index\r\n",
        "  ft_trn_series.index=trn_series.index\r\n",
        "  ft_tst_series = pd.merge(tst_series.to_frame(tst_series.name),\r\n",
        "                           averages.reset_index().rename(columns={'index':target.name, target.name:'average'}),\r\n",
        "                           on=tst_series.name,\r\n",
        "                           how='left')['average'].rename(trn_series.name+'_mean').fillna(prior)\r\n",
        "  \r\n",
        "  ft_tst_series.index = tst_series.index\r\n",
        "  return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Ld868Onp16"
      },
      "source": [
        "### encoding categorical vars.\r\n",
        ": *ps_car_11_cat_te*의 집합원이 많으므로 encoding 처리가 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "346Uu40xpj9P"
      },
      "source": [
        "train_encoded, test_encoded = target_encode(train['ps_car_11_cat'],test['ps_car_11_cat'],\r\n",
        "                                            target=train.target,\r\n",
        "                                            min_samples_leaf=100,\r\n",
        "                                            smoothing=10,\r\n",
        "                                            noise_level=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RTCxV_Vq6zm"
      },
      "source": [
        "# Encoding train set\r\n",
        "train['ps_car_11_cat_te'] = train_encoded\r\n",
        "train.drop('ps_car_11_cat',axis=1, inplace=True)\r\n",
        "meta.loc['ps_car_11_cat','keep'] = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jhO7nCjrUR9"
      },
      "source": [
        "# Encoding test set\r\n",
        "test['ps_car_11_cat_te'] = test_encoded\r\n",
        "test.drop('ps_car_11_cat',axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug13MsLqm0RG"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZtZXJKsHQt"
      },
      "source": [
        "## Categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQRhOeGhsKTd"
      },
      "source": [
        "v = meta[(meta.level=='nominal') & (meta.keep)].index\r\n",
        "\r\n",
        "for f in v:\r\n",
        "  plt.figure()\r\n",
        "  fig, ax = plt.subplots(figsize=(20,10))\r\n",
        "\r\n",
        "  # categorical 변수의 라벨별 target=1의 비율\r\n",
        "  cat_perc = train[[f,'target']].groupby([f],as_index=False).mean()\r\n",
        "  cat_perc.sort_values(by='target',ascending=False, inplace=True)\r\n",
        "\r\n",
        "  # Bar plot\r\n",
        "  sns.barplot(ax=ax, x=f, y='target', data=cat_perc, order=cat_perc[f])\r\n",
        "  plt.ylabel('% target',fontsize=18)\r\n",
        "  plt.xlabel(f,fontsize=18)\r\n",
        "  plt.tick_params(axis='both',which='major',labelsize=18)\r\n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mD1iNj_2uQVz"
      },
      "source": [
        "- *ps_car_09_cat*, *ps_car_07_cat*, *ps_car_01_cat*, *ps_ind_05_cat*, *ps_ind_04_cat*, *ps_ind_02_cat* 6개의 변수들은 결측값의 target=1 비율이 가장 높다->결측값을 쉽게 제거할 수 없다고 판단"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K682O23uzn8"
      },
      "source": [
        "## Interval variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbJns1z7w5am"
      },
      "source": [
        "def corr_heatmap(v):\r\n",
        "  correlations = train[v].corr()\r\n",
        "  cmap = sns.diverging_palette(220,10,as_cmap=True)\r\n",
        "  fig,ax = plt.subplots(figsize=(10,10))\r\n",
        "  sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f',\r\n",
        "              square=True,linewidths=.5,annot=True,cbar_kws={'shrink':.75})\r\n",
        "  plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXmH43G2u2TL"
      },
      "source": [
        "v = meta[(meta.level=='interval') & (meta.keep)].index\r\n",
        "corr_heatmap(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9HPjGJXx8Z0"
      },
      "source": [
        "- interval 변수 사이에 다중공선성이 높은 변수가 존재한다\r\n",
        "  - (**0.7**) *ps_reg_02*와 *ps_reg_03*\r\n",
        "  - (**0.67**) *ps_car_12*와 *ps_car_13*\r\n",
        "  - (**0.58**) *ps_car_12*와 *ps_car_14*\r\n",
        "  - (**0.53**) *ps_car_13*와 *ps_car_15*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D09DffOze1J"
      },
      "source": [
        "### Multicollinearity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCvkHa3-za1y"
      },
      "source": [
        "s = train.sample(frac=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Rfmsozzm8S"
      },
      "source": [
        "#### *ps_reg_02*와 *ps_reg_03*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QGdO7slz3HC"
      },
      "source": [
        "sns.lmplot(x='ps_reg_02', y='ps_reg_03',data=s,\r\n",
        "           hue='target',palette='Set1',scatter_kws={'alpha':.3})\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzC_Pggn1FaD"
      },
      "source": [
        "- target=1과 target=0의 회귀선이 거의 일치한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Geq47zr8z3ff"
      },
      "source": [
        "#### *ps_car_12*와 *ps_car13*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpICfup-z6jl"
      },
      "source": [
        "sns.lmplot(x='ps_car_12', y='ps_car_13',data=s,\r\n",
        "           hue='target',palette='Set1',scatter_kws={'alpha':.3})\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JbeN1uCz62g"
      },
      "source": [
        "#### *ps_car_12*와 *ps_car14*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PytjhKbKz9ZT"
      },
      "source": [
        "sns.lmplot(x='ps_car_12', y='ps_car_14',data=s,\r\n",
        "           hue='target',palette='Set1',scatter_kws={'alpha':.3})\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zh0YXN_z9qm"
      },
      "source": [
        "#### *ps_car_13*와 *ps_car15*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1Dhc2HVz-3N"
      },
      "source": [
        "sns.lmplot(x='ps_car_15', y='ps_car_13',data=s,\r\n",
        "           hue='target',palette='Set1',scatter_kws={'alpha':.3})\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1Tf2fofOsq8"
      },
      "source": [
        "- 다중공선성이 높은 변수들이 존재하지만, 그 수가 적기 때문에 해당 커널에서는 PCA를 진행하지 않는다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWZTB0VtwujZ"
      },
      "source": [
        "## Ordinal variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X9VLz4-wxfJ"
      },
      "source": [
        "v = meta[(meta.level=='ordinal') & (meta.keep)].index\r\n",
        "corr_heatmap(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9UZ-nsxBGm"
      },
      "source": [
        "- ordinal 변수 사이에는 강한 상관관계를 가진 다중공선성이 높은 변수가 없는 것으로 볼 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFQ0foFPm2eS"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsqvZ3QP2NTE"
      },
      "source": [
        "## dummy variables\r\n",
        ": dummification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMX00DtK2P5r"
      },
      "source": [
        "print(f'Before dummification: {train.shape[1]} vars.')\r\n",
        "\r\n",
        "v = meta[(meta.level=='nominal') & (meta.keep)].index #nominal 변수의 dummy화\r\n",
        "train = pd.get_dummies(train, columns=v, drop_first=True)\r\n",
        "print(f'After dummification: {train.shape[1]} vars.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqL_hZTwbDyg"
      },
      "source": [
        "# test dset\r\n",
        "print(f'Before dummification: {test.shape[1]} vars.')\r\n",
        "\r\n",
        "v = meta[(meta.level=='nominal') & (meta.keep)].index #nominal 변수의 dummy화\r\n",
        "test = pd.get_dummies(test, columns=v, drop_first=True)\r\n",
        "print(f'After dummification: {test.shape[1]} vars.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce8YQg0-3noQ"
      },
      "source": [
        "## interaction variables\r\n",
        ": interval 변수들의 interaction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGco1-wX3trP"
      },
      "source": [
        "print(f'Before interactions: {train.shape[1]} vars.')\r\n",
        "\r\n",
        "v = meta[(meta.level=='interval') & (meta.keep)].index\r\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\r\n",
        "\r\n",
        "interactions = pd.DataFrame(data=poly.fit_transform(train[v]),\r\n",
        "                            columns=poly.get_feature_names(v))\r\n",
        "interactions.drop(v,axis=1, inplace=True) #interaction 변수 외 제거\r\n",
        "train = pd.concat([train, interactions], axis=1)\r\n",
        "print(f'After interactions: {train.shape[1]} vars.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3clyskXbPl6"
      },
      "source": [
        "# test dset\r\n",
        "\r\n",
        "print(f'Before interactions: {test.shape[1]} vars.')\r\n",
        "\r\n",
        "v = meta[(meta.level=='interval') & (meta.keep)].index\r\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\r\n",
        "\r\n",
        "interactions = pd.DataFrame(data=poly.fit_transform(test[v]),\r\n",
        "                            columns=poly.get_feature_names(v))\r\n",
        "interactions.drop(v,axis=1, inplace=True) #interaction 변수 외 제거\r\n",
        "test = pd.concat([test, interactions], axis=1)\r\n",
        "print(f'After interactions: {test.shape[1]} vars.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSvcxwhAm5Ee"
      },
      "source": [
        "# Feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Cfvps4q3lJG"
      },
      "source": [
        "## VarianceThreshold\r\n",
        ": remove low or zero variance features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ychpbRo0JPV4"
      },
      "source": [
        "selector = VarianceThreshold(threshold=.01) #variance 0.01 이하 변수 선택\r\n",
        "selector.fit(train.drop(['id','target'],axis=1)) #id, target 제외하고 변수 선택\r\n",
        "\r\n",
        "f = np.vectorize(lambda x: not x)\r\n",
        "\r\n",
        "v = train.drop(['id','target'],axis=1).columns[f(selector.get_support())] #변수명 추출\r\n",
        "print(f'{len(v)} variables have too low variance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAO5yQ6sKuT_"
      },
      "source": [
        "- 총 **28**개의 변수가 제거 대상->더 많은 변수 제거해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YCJbBEcLTkD"
      },
      "source": [
        "## SelectFromModel\r\n",
        ": RandomForest 모델을 활용해서 변수 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeX0xwQnLaIZ"
      },
      "source": [
        "X_train = train.drop(['id','target'],axis=1)\r\n",
        "y_train = train['target']\r\n",
        "\r\n",
        "feat_labels = X_train.columns #features만 추출\r\n",
        "\r\n",
        "rf = RandomForestClassifier(n_estimators=1000, random_state=0, n_jobs=-1) #랜덤포레스트 모델\r\n",
        "rf.fit(X_train, y_train) #모델 학습\r\n",
        "\r\n",
        "importances = rf.feature_importances_ #학습 결과에 따른 feature importances\r\n",
        "\r\n",
        "# print features importances\r\n",
        "indices = np.argsort(rf.feature_importances_)[::-1]\r\n",
        "#for f in range(X_train.shape[1]):\r\n",
        "#  print(\"%2d) %-*s %f\" % (f+1, 30, feat_labels[indices[f]], importances[indices[f]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQgsEhy7MgR4"
      },
      "source": [
        "# select from RandomForest\r\n",
        "print(f'Before selection:{X_train.shape[1]}')\r\n",
        "\r\n",
        "sfm = SelectFromModel(rf, threshold='median', prefit=True) #selection-변수의 절반만 선택(중요도 상위50%)\r\n",
        "n_features = sfm.transform(X_train).shape[1] #selection 결과-선택된 변수 개수\r\n",
        "print(f'After selection:{n_features}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USoCMV-aNXPy"
      },
      "source": [
        "selected_vars = list(feat_labels[sfm.get_support()]) #선택된 변수명 list\r\n",
        "train = train[selected_vars + ['target']] #id 제외한 trainset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD-rMYLccKEd"
      },
      "source": [
        "# test dset\r\n",
        "test = test[selected_vars] #id 제외한 testset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jziaLFom7CL"
      },
      "source": [
        "# Feature scaling\r\n",
        ": 표준화 Standardization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRX7uolVNyFI"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "scaler.fit_transform(train.drop(['target'], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLqAEEWoc2Xf"
      },
      "source": [
        "# test dset\r\n",
        "scaler.fit_transform(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usHbTMqlRr2G"
      },
      "source": [
        "# XGBoost CV(LB .284)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3QcwpivSVop"
      },
      "source": [
        "## Loading Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HFFbXXZSZtU"
      },
      "source": [
        "# model\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "# model selection\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "#??\r\n",
        "from numba import jit\r\n",
        "import gc\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StjPlKdIR1XA"
      },
      "source": [
        "max_rounds = 400\r\n",
        "optimize_rounds = False\r\n",
        "learning_rate = 0.07\r\n",
        "early_stopping_rounds = 50 #early stopping 기준"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKlkezKlTRQK"
      },
      "source": [
        "# gini\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-S2l9mTWdl"
      },
      "source": [
        "# gini 계수\r\n",
        "# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\r\n",
        "\r\n",
        "@jit\r\n",
        "def eval_gini(y_true, y_prob):\r\n",
        "  y_true = np.asarray(y_true)\r\n",
        "  y_true = y_true[np.argsort(y_prob)]\r\n",
        "  ntrue, gini, delta = 0,0,0\r\n",
        "  n = len(y_true)\r\n",
        "\r\n",
        "  for i in range(n-1,-1, -1):\r\n",
        "    y_i = y_true[i]\r\n",
        "    ntrue += y_i\r\n",
        "    gini += y_i *delta\r\n",
        "    delta += 1-y_i\r\n",
        "  \r\n",
        "  gini = 1-2*gini / (ntrue*(n-ntrue))\r\n",
        "  return gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKzc_YSBURjm"
      },
      "source": [
        "\r\n",
        "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\r\n",
        "\r\n",
        "def gini_xgb(preds, dtrain):\r\n",
        "  labels = dtain.get_label()\r\n",
        "  gini_score = -eval_gini(labels, preds)\r\n",
        "  return [('gini',gini_score)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvWYjFBWWZi3"
      },
      "source": [
        "- data handling은 **Data Preparation & Exploration**을 기반한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIxbo_CbXHem"
      },
      "source": [
        "y = train['target']\r\n",
        "\r\n",
        "y_valid_pred = 0*y\r\n",
        "t_test_pred = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z1u_5Q2XQmF"
      },
      "source": [
        "# K-fold\r\n",
        ": `k=5` 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZSl7eSUZcaK"
      },
      "source": [
        "train_df = train.drop(['id','target'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcKFOOxDXSZB"
      },
      "source": [
        "# K-fold 설정\r\n",
        "\r\n",
        "k = 5\r\n",
        "kf = KFold(n_splits=k, random_state=1, shuffle=True)\r\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgV7qWPTXfyJ"
      },
      "source": [
        "# model 구축\r\n",
        "model = XGBClassifier(\r\n",
        "    n_estimators=max_rounds,\r\n",
        "    max_depth=4,\r\n",
        "    objective='binary:logistic',\r\n",
        "    learning_rate=learning_rate,\r\n",
        "    subsample=0.8,\r\n",
        "    min_child_weight=6,\r\n",
        "    colsample_bytree=0.8,\r\n",
        "    scale_pos_weight=1.6,\r\n",
        "    gamma=10,\r\n",
        "    reg_alpha=8,\r\n",
        "    reg_lambda=1.3\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q56X4nuDYmtD"
      },
      "source": [
        "# K-fold 실행\r\n",
        "\r\n",
        "for i,(train_index,test_index) in enumerate(kf.split(train_df)):\r\n",
        "  y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\r\n",
        "  X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\r\n",
        "  X_test = test.copy()\r\n",
        "  print('\\nFold ',i)\r\n",
        "\r\n",
        "  # encoding 처리는 생략\r\n",
        "\r\n",
        "  # fold\r\n",
        "  if optimize_rounds:\r\n",
        "    eval_set=[(X_valid,y_valid)]\r\n",
        "    fit_model = model.fit(X_train, y_train,\r\n",
        "                          eval_set=eval_set,\r\n",
        "                          eval_metric=gini_xgb,\r\n",
        "                          early_stopping_rounds=early_stopping_rounds,\r\n",
        "                          verbose=False)\r\n",
        "    prinf(f'  Best N trees = {model.best_ntree_limit}')\r\n",
        "    print(f'  Best gini = {model.best_score}')\r\n",
        "  else:\r\n",
        "    fit_model = model.fit(X_train, y_train)\r\n",
        "\r\n",
        "  # validation predictions\r\n",
        "  pred = fit_model.predict_proba(X_valid)[:,1]\r\n",
        "  print(f'  Gini = {eval_gini(y_valid, pred)}')\r\n",
        "  y_valid_pred.iloc[test_index] = pred\r\n",
        "\r\n",
        "  # test dset prediction\r\n",
        "  y_test_pred += fit_model.predict_proba(X_test)[:,1]\r\n",
        "  del X_test, X_train, X_valid, y_train #초기화\r\n",
        "\r\n",
        "y_test_pred /= k #predictions 평균\r\n",
        "print(f'Gini for full training set:{eval_gini(y,y_valid_pred)}') #최종 gini계수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqKj6-yyfXf1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}